{
  "gpt4_7648724251945762349_-6157158459951558851_2025-03-04T17:03:31.391235": {
    "overall_score": 0.6766009577903997,
    "timestamp": "2025-03-04T17:03:31.391985",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4200913242009132,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4200913242009132,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4200913242009132,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4200913242009132,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.6,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4200913242009132,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4200913242009132,
          "structure_score": 0.6,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7648724251945762349_-1925668123965865361_2025-03-04T17:03:31.392335": {
    "overall_score": 0.6789397483015925,
    "timestamp": "2025-03-04T17:03:31.393103",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4337899543378995,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4337899543378995,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4337899543378995,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4337899543378995,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.6,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4337899543378995,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4337899543378995,
          "structure_score": 0.6,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7648724251945762349_3813331544101891243_2025-03-04T17:03:31.393470": {
    "overall_score": 0.6781601514645283,
    "timestamp": "2025-03-04T17:03:31.394790",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4292237442922374,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.6,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7648724251945762349_-2742777488961769245_2025-03-04T17:03:31.395346": {
    "overall_score": 0.6781601514645283,
    "timestamp": "2025-03-04T17:03:31.397924",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4292237442922374,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.6,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4292237442922374,
          "structure_score": 0.6,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2069479718291944609_-873426763653398608_2025-03-04T17:03:31.400344": {
    "overall_score": 0.6617666446934739,
    "timestamp": "2025-03-04T17:03:31.401861",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4189189189189189,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4189189189189189,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4189189189189189,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4189189189189189,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4189189189189189,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.4189189189189189,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2069479718291944609_-8457822123160966473_2025-03-04T17:03:31.402385": {
    "overall_score": 0.6640738299274884,
    "timestamp": "2025-03-04T17:03:31.404246",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.43243243243243246,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.43243243243243246,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.43243243243243246,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.43243243243243246,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.43243243243243246,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.43243243243243246,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2069479718291944609_-3750791650055381568_2025-03-04T17:03:31.404895": {
    "overall_score": 0.663304768182817,
    "timestamp": "2025-03-04T17:03:31.407005",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.42792792792792794,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2069479718291944609_-8316462242865906103_2025-03-04T17:03:31.407710": {
    "overall_score": 0.663304768182817,
    "timestamp": "2025-03-04T17:03:31.409720",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.42792792792792794,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 1.0,
          "completeness": 0.42792792792792794,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_8341263838325193855_-8749702149120901321_2025-03-04T17:03:31.414363": {
    "overall_score": 0.6590368980612883,
    "timestamp": "2025-03-04T17:03:31.416937",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.40293040293040294,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.40293040293040294,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.40293040293040294,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.40293040293040294,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.40293040293040294,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.40293040293040294,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_8341263838325193855_1408917033707941367_2025-03-04T17:03:31.418069": {
    "overall_score": 0.6609130706691683,
    "timestamp": "2025-03-04T17:03:31.420960",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.4139194139194139,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.4139194139194139,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4139194139194139,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.4139194139194139,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.4139194139194139,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.4139194139194139,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_8341263838325193855_7318213752153395033_2025-03-04T17:03:31.421854": {
    "overall_score": 0.6602876797998749,
    "timestamp": "2025-03-04T17:03:31.424222",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.41025641025641024,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_8341263838325193855_7780240647420188050_2025-03-04T17:03:31.425152": {
    "overall_score": 0.6602876797998749,
    "timestamp": "2025-03-04T17:03:31.427702",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.41025641025641024,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.5,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 1.0,
          "completeness": 0.41025641025641024,
          "structure_score": 0.5,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_2148201681762242958_4170399587640717500_2025-03-04T20:06:48.039915": {
    "overall_score": 0.8071294559099438,
    "timestamp": "2025-03-04T20:06:48.043536",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7615384615384615,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_2148201681762242958_2447467899267169708_2025-03-04T20:06:48.045184": {
    "overall_score": 0.7125703564727955,
    "timestamp": "2025-03-04T20:06:48.048622",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_2148201681762242958_-1421819484652025487_2025-03-04T20:06:48.049864": {
    "overall_score": 0.6833020637898687,
    "timestamp": "2025-03-04T20:06:48.053285",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_2148201681762242958_-784763777290547156_2025-03-04T20:06:48.054740": {
    "overall_score": 0.6478424015009382,
    "timestamp": "2025-03-04T20:06:48.058834",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2076923076923077,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1023439571622351013_-1558463060628949251_2025-03-04T20:06:48.065169": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-04T20:06:48.068814",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1023439571622351013_2447467899267169708_2025-03-04T20:06:48.070862": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-04T20:06:48.074714",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1023439571622351013_-1421819484652025487_2025-03-04T20:06:48.076068": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-04T20:06:48.080007",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1023439571622351013_-784763777290547156_2025-03-04T20:06:48.081404": {
    "overall_score": 0.6891622481442206,
    "timestamp": "2025-03-04T20:06:48.085875",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9565217391304348,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7980721252374065787_6488362545228041654_2025-03-04T20:06:48.092089": {
    "overall_score": 0.7839721254355402,
    "timestamp": "2025-03-04T20:06:48.097021",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.6428571428571429,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7980721252374065787_2447467899267169708_2025-03-04T20:06:48.098559": {
    "overall_score": 0.7337979094076654,
    "timestamp": "2025-03-04T20:06:48.103126",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3857142857142857,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7980721252374065787_-1421819484652025487_2025-03-04T20:06:48.104659": {
    "overall_score": 0.6794425087108015,
    "timestamp": "2025-03-04T20:06:48.109530",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7980721252374065787_-784763777290547156_2025-03-04T20:06:48.111086": {
    "overall_score": 0.694076655052265,
    "timestamp": "2025-03-04T20:06:48.116164",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_4835012566813063071_-1392822590025476237_2025-03-04T20:06:48.123198": {
    "overall_score": 0.8090592334494773,
    "timestamp": "2025-03-04T20:06:48.128220",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7714285714285714,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_4835012566813063071_2447467899267169708_2025-03-04T20:06:48.130157": {
    "overall_score": 0.7212543554006969,
    "timestamp": "2025-03-04T20:06:48.135154",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32142857142857145,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_4835012566813063071_-1421819484652025487_2025-03-04T20:06:48.137131": {
    "overall_score": 0.6599193566059649,
    "timestamp": "2025-03-04T20:06:48.143018",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9591194968553459,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_4835012566813063071_-784763777290547156_2025-03-04T20:06:48.145051": {
    "overall_score": 0.6171060416803629,
    "timestamp": "2025-03-04T20:06:48.150680",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6226415094339622,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2143833425341420068_4569053843927389470_2025-03-04T20:06:48.158104": {
    "overall_score": 0.7831957230078138,
    "timestamp": "2025-03-04T20:06:48.163988",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.825,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7872892347600519,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2143833425341420068_2447467899267169708_2025-03-04T20:06:48.165957": {
    "overall_score": 0.593027743507007,
    "timestamp": "2025-03-04T20:06:48.172093",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.44487678339818415,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2143833425341420068_-1421819484652025487_2025-03-04T20:06:48.174361": {
    "overall_score": 0.548027585334219,
    "timestamp": "2025-03-04T20:06:48.180645",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3955901426718547,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2143833425341420068_-784763777290547156_2025-03-04T20:06:48.183193": {
    "overall_score": 0.5389674480402391,
    "timestamp": "2025-03-04T20:06:48.189071",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25680933852140075,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3835783564394830165_6499962056419009701_2025-03-04T20:10:34.517271": {
    "overall_score": 0.8071294559099438,
    "timestamp": "2025-03-04T20:10:34.524444",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7615384615384615,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3835783564394830165_-978799280340175750_2025-03-04T20:10:34.526913": {
    "overall_score": 0.7125703564727955,
    "timestamp": "2025-03-04T20:10:34.533888",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3835783564394830165_6314767000331637707_2025-03-04T20:10:34.535949": {
    "overall_score": 0.6833020637898687,
    "timestamp": "2025-03-04T20:10:34.543021",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3835783564394830165_-64265532204665575_2025-03-04T20:10:34.545056": {
    "overall_score": 0.6478424015009382,
    "timestamp": "2025-03-04T20:10:34.552023",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2076923076923077,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5688385227457838803_-758048642406912200_2025-03-04T20:10:34.559619": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-04T20:10:34.566873",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5688385227457838803_-978799280340175750_2025-03-04T20:10:34.569036": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-04T20:10:34.576578",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5688385227457838803_6314767000331637707_2025-03-04T20:10:34.578816": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-04T20:10:34.586172",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5688385227457838803_-64265532204665575_2025-03-04T20:10:34.588519": {
    "overall_score": 0.6891622481442206,
    "timestamp": "2025-03-04T20:10:34.595507",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9565217391304348,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_2205675236354100780_-7249397537848995333_2025-03-04T20:10:34.603451": {
    "overall_score": 0.7839721254355402,
    "timestamp": "2025-03-04T20:10:34.611945",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.6428571428571429,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_2205675236354100780_-978799280340175750_2025-03-04T20:10:34.614251": {
    "overall_score": 0.7337979094076654,
    "timestamp": "2025-03-04T20:10:34.621877",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3857142857142857,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_2205675236354100780_6314767000331637707_2025-03-04T20:10:34.624553": {
    "overall_score": 0.6794425087108015,
    "timestamp": "2025-03-04T20:10:34.632636",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_2205675236354100780_-64265532204665575_2025-03-04T20:10:34.635312": {
    "overall_score": 0.694076655052265,
    "timestamp": "2025-03-04T20:10:34.643605",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-1064293230462487456_7267050762586575218_2025-03-04T20:10:34.766952": {
    "overall_score": 0.8090592334494773,
    "timestamp": "2025-03-04T20:10:34.775681",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7714285714285714,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-1064293230462487456_-978799280340175750_2025-03-04T20:10:34.778884": {
    "overall_score": 0.7212543554006969,
    "timestamp": "2025-03-04T20:10:34.787414",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32142857142857145,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-1064293230462487456_6314767000331637707_2025-03-04T20:10:34.790556": {
    "overall_score": 0.6599193566059649,
    "timestamp": "2025-03-04T20:10:34.799697",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9591194968553459,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-1064293230462487456_-64265532204665575_2025-03-04T20:10:34.802701": {
    "overall_score": 0.6171060416803629,
    "timestamp": "2025-03-04T20:10:34.811882",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6226415094339622,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_534493795516744800_1456086432443163102_2025-03-04T20:10:34.819836": {
    "overall_score": 0.7831957230078138,
    "timestamp": "2025-03-04T20:10:34.828694",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.825,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7872892347600519,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_534493795516744800_-978799280340175750_2025-03-04T20:10:34.838636": {
    "overall_score": 0.593027743507007,
    "timestamp": "2025-03-04T20:10:34.870869",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.44487678339818415,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_534493795516744800_6314767000331637707_2025-03-04T20:10:34.875245": {
    "overall_score": 0.548027585334219,
    "timestamp": "2025-03-04T20:10:34.908211",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3955901426718547,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_534493795516744800_-64265532204665575_2025-03-04T20:10:34.911960": {
    "overall_score": 0.5389674480402391,
    "timestamp": "2025-03-04T20:10:34.924366",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25680933852140075,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1863873532685192531_576564866311069535_2025-03-04T23:18:29.331311": {
    "overall_score": 0.8071294559099438,
    "timestamp": "2025-03-04T23:18:29.352941",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7615384615384615,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1863873532685192531_8542904971329014338_2025-03-04T23:18:29.470330": {
    "overall_score": 0.7125703564727955,
    "timestamp": "2025-03-04T23:18:29.480201",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1863873532685192531_6570875111201062337_2025-03-04T23:18:29.483658": {
    "overall_score": 0.6833020637898687,
    "timestamp": "2025-03-04T23:18:29.494215",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1863873532685192531_-1603804165534160105_2025-03-04T23:18:29.497166": {
    "overall_score": 0.6478424015009382,
    "timestamp": "2025-03-04T23:18:29.507052",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2076923076923077,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_35018922793727760_6271612333362350567_2025-03-04T23:18:29.516110": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-04T23:18:29.529138",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_35018922793727760_8542904971329014338_2025-03-04T23:18:29.532463": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-04T23:18:29.543502",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_35018922793727760_6570875111201062337_2025-03-04T23:18:29.546427": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-04T23:18:29.556815",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_35018922793727760_-1603804165534160105_2025-03-04T23:18:29.559960": {
    "overall_score": 0.6891622481442206,
    "timestamp": "2025-03-04T23:18:29.570765",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9565217391304348,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1503403699831215609_-7025841832545708868_2025-03-04T23:18:29.579549": {
    "overall_score": 0.7839721254355402,
    "timestamp": "2025-03-04T23:18:29.590499",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.6428571428571429,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.7142857142857143,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1503403699831215609_8542904971329014338_2025-03-04T23:18:29.593619": {
    "overall_score": 0.7337979094076654,
    "timestamp": "2025-03-04T23:18:29.605103",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3857142857142857,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1503403699831215609_6570875111201062337_2025-03-04T23:18:29.608702": {
    "overall_score": 0.6794425087108015,
    "timestamp": "2025-03-04T23:18:29.622684",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1503403699831215609_-1603804165534160105_2025-03-04T23:18:29.626097": {
    "overall_score": 0.694076655052265,
    "timestamp": "2025-03-04T23:18:29.637970",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-8179984705403960470_-2998003031052335709_2025-03-04T23:18:29.646539": {
    "overall_score": 0.8090592334494773,
    "timestamp": "2025-03-04T23:18:29.657647",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7714285714285714,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8179984705403960470_8542904971329014338_2025-03-04T23:18:29.661094": {
    "overall_score": 0.7212543554006969,
    "timestamp": "2025-03-04T23:18:29.672900",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32142857142857145,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.35714285714285715,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8179984705403960470_6570875111201062337_2025-03-04T23:18:29.676514": {
    "overall_score": 0.6599193566059649,
    "timestamp": "2025-03-04T23:18:29.688865",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9591194968553459,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.9591194968553459,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8179984705403960470_-1603804165534160105_2025-03-04T23:18:29.692356": {
    "overall_score": 0.6171060416803629,
    "timestamp": "2025-03-04T23:18:29.706433",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6226415094339622,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6226415094339622,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2780403845054250024_8495739777434573607_2025-03-04T23:18:29.715231": {
    "overall_score": 0.7831957230078138,
    "timestamp": "2025-03-04T23:18:29.727604",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.825,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7872892347600519,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 22,
          "overlap_ratio": 0.9166666666666666,
          "completeness": 0.7872892347600519,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2780403845054250024_8542904971329014338_2025-03-04T23:18:29.731603": {
    "overall_score": 0.593027743507007,
    "timestamp": "2025-03-04T23:18:29.744231",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.44487678339818415,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.44487678339818415,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2780403845054250024_6570875111201062337_2025-03-04T23:18:29.748110": {
    "overall_score": 0.548027585334219,
    "timestamp": "2025-03-04T23:18:29.761130",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3955901426718547,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.3955901426718547,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2780403845054250024_-1603804165534160105_2025-03-04T23:18:29.765101": {
    "overall_score": 0.5389674480402391,
    "timestamp": "2025-03-04T23:18:29.778006",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25680933852140075,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.25680933852140075,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2226038470386937081_3499380421993097890_2025-03-05T03:46:33.543548": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:46:33.557699",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2226038470386937081_-1754728012741895102_2025-03-05T03:46:33.561484": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T03:46:33.574963",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2226038470386937081_3254137498696555257_2025-03-05T03:46:33.579002": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T03:46:33.592797",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2226038470386937081_7083775591352819366_2025-03-05T03:46:33.596641": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T03:46:33.610372",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_4363025613660257086_3280537774923174912_2025-03-05T03:46:33.614848": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:46:33.628752",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_4363025613660257086_-1754728012741895102_2025-03-05T03:46:33.632625": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T03:46:33.646979",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_4363025613660257086_3254137498696555257_2025-03-05T03:46:33.650982": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T03:46:33.665318",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_4363025613660257086_7083775591352819366_2025-03-05T03:46:33.669348": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T03:46:33.683870",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_8970320024430579113_-6276557748768227513_2025-03-05T03:46:33.688573": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:46:33.703069",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_8970320024430579113_-1754728012741895102_2025-03-05T03:46:33.707612": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T03:46:33.722372",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_8970320024430579113_3254137498696555257_2025-03-05T03:46:33.726455": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T03:46:33.742009",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_8970320024430579113_7083775591352819366_2025-03-05T03:46:33.745856": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T03:46:33.760924",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5925742346091449713_-3094707282944612197_2025-03-05T03:54:52.632710": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:54:52.648126",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5925742346091449713_-5848071187545454705_2025-03-05T03:54:52.652847": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T03:54:52.668120",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5925742346091449713_-82812468427696420_2025-03-05T03:54:52.672044": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T03:54:52.687782",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5925742346091449713_6754040008365914104_2025-03-05T03:54:52.691955": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T03:54:52.707592",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-665254467754847169_-8880088020878266241_2025-03-05T03:54:52.712781": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:54:52.728563",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-665254467754847169_-5848071187545454705_2025-03-05T03:54:52.733042": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T03:54:52.748883",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-665254467754847169_-82812468427696420_2025-03-05T03:54:52.753130": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T03:54:52.769729",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-665254467754847169_6754040008365914104_2025-03-05T03:54:52.774162": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T03:54:52.790232",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-7258724749607543867_-7958558970445841945_2025-03-05T03:54:52.795359": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T03:54:52.812032",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-7258724749607543867_-5848071187545454705_2025-03-05T03:54:52.816627": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T03:54:52.833237",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-7258724749607543867_-82812468427696420_2025-03-05T03:54:52.837733": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T03:54:52.854171",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-7258724749607543867_6754040008365914104_2025-03-05T03:54:52.858872": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T03:54:52.875776",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3373167389615809010_-4910880986414578334_2025-03-05T04:11:24.929233": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:11:24.954699",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3373167389615809010_-7715018863313542463_2025-03-05T04:11:24.961984": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T04:11:25.047790",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3373167389615809010_-3817982092437308194_2025-03-05T04:11:25.061278": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:11:25.133923",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3373167389615809010_2787345169698998622_2025-03-05T04:11:25.141135": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T04:11:25.180853",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_960497849612658183_1848977508678051487_2025-03-05T04:11:25.189262": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:11:25.216833",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_960497849612658183_-7715018863313542463_2025-03-05T04:11:25.223942": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T04:11:25.252039",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_960497849612658183_-3817982092437308194_2025-03-05T04:11:25.260024": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:11:25.291354",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_960497849612658183_2787345169698998622_2025-03-05T04:11:25.299597": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T04:11:25.330260",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5119182087275064655_-4539009480267698166_2025-03-05T04:11:25.339211": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:11:25.370397",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5119182087275064655_-7715018863313542463_2025-03-05T04:11:25.378823": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T04:11:25.410594",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5119182087275064655_-3817982092437308194_2025-03-05T04:11:25.419031": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T04:11:25.450904",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5119182087275064655_2787345169698998622_2025-03-05T04:11:25.459744": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T04:11:25.493652",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1740832504840028797_7203820274375888912_2025-03-05T04:12:02.459836": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:12:02.532377",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1740832504840028797_-3747847917418261110_2025-03-05T04:12:02.554804": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-05T04:12:02.637767",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1740832504840028797_-9039075105591931322_2025-03-05T04:12:02.659168": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:12:02.731283",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1740832504840028797_4508896086224214931_2025-03-05T04:12:02.832659": {
    "overall_score": 0.6760975609756099,
    "timestamp": "2025-03-05T04:12:02.936464",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.88,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-6137563076962363371_3863588508397744292_2025-03-05T04:12:05.930463": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:12:06.452501",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-6137563076962363371_-3747847917418261110_2025-03-05T04:12:08.363781": {
    "overall_score": 0.728780487804878,
    "timestamp": "2025-03-05T04:12:09.024467",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.36000000000000004,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-6137563076962363371_-9039075105591931322_2025-03-05T04:12:09.063255": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:12:09.245921",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-6137563076962363371_4508896086224214931_2025-03-05T04:12:09.314591": {
    "overall_score": 0.662652856665553,
    "timestamp": "2025-03-05T04:12:09.462074",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5706687429417943759_-9157055337553224545_2025-03-05T04:12:13.119415": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-05T04:12:13.193201",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5706687429417943759_-3747847917418261110_2025-03-05T04:12:13.217875": {
    "overall_score": 0.738359201773836,
    "timestamp": "2025-03-05T04:12:13.292613",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.40909090909090906,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5706687429417943759_-9039075105591931322_2025-03-05T04:12:13.315974": {
    "overall_score": 0.6931263858093127,
    "timestamp": "2025-03-05T04:12:13.396076",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5706687429417943759_4508896086224214931_2025-03-05T04:12:13.436718": {
    "overall_score": 0.6693313105379858,
    "timestamp": "2025-03-05T04:12:13.521420",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.868421052631579,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5556142039512785150_-4328842729466784854_2025-03-05T04:18:43.767688": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:18:43.793395",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5556142039512785150_3190372854207199071_2025-03-05T04:18:43.800556": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T04:18:43.825776",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5556142039512785150_6124053986436619332_2025-03-05T04:18:43.833136": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:18:43.859482",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5556142039512785150_-2971039030774832956_2025-03-05T04:18:43.867593": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T04:18:43.894603",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-8812516445961480324_6625532507440964358_2025-03-05T04:18:43.903260": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:18:43.930731",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8812516445961480324_3190372854207199071_2025-03-05T04:18:43.939051": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T04:18:43.967853",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8812516445961480324_6124053986436619332_2025-03-05T04:18:43.976181": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:18:44.004419",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8812516445961480324_-2971039030774832956_2025-03-05T04:18:44.012714": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T04:18:44.059396",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5601008457175306799_8386084733568239030_2025-03-05T04:18:44.068627": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:18:44.097382",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5601008457175306799_3190372854207199071_2025-03-05T04:18:44.106082": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T04:18:44.135463",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5601008457175306799_6124053986436619332_2025-03-05T04:18:44.146234": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T04:18:44.181877",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5601008457175306799_-2971039030774832956_2025-03-05T04:18:44.191843": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T04:18:44.226083",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-1961810008853989760_-2627246917538301631_2025-03-05T04:19:22.188357": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:19:22.887085",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-1961810008853989760_8100950332181724293_2025-03-05T04:19:24.232419": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-05T04:19:24.399837",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-1961810008853989760_6480087563572290976_2025-03-05T04:19:24.433667": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:19:24.563169",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-1961810008853989760_4838381025718951793_2025-03-05T04:19:24.623024": {
    "overall_score": 0.6760975609756099,
    "timestamp": "2025-03-05T04:19:24.716771",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.88,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3485107743033789015_-7489501058153374450_2025-03-05T04:19:26.934343": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:19:27.047015",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3485107743033789015_8100950332181724293_2025-03-05T04:19:27.079496": {
    "overall_score": 0.728780487804878,
    "timestamp": "2025-03-05T04:19:27.198421",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.36000000000000004,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3485107743033789015_6480087563572290976_2025-03-05T04:19:27.239692": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:19:27.369402",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3485107743033789015_4838381025718951793_2025-03-05T04:19:27.405210": {
    "overall_score": 0.662652856665553,
    "timestamp": "2025-03-05T04:19:27.510408",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7474834536945198615_6539041899497504158_2025-03-05T04:19:29.580720": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-05T04:19:29.681359",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7474834536945198615_8100950332181724293_2025-03-05T04:19:29.711803": {
    "overall_score": 0.738359201773836,
    "timestamp": "2025-03-05T04:19:29.956760",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.40909090909090906,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7474834536945198615_6480087563572290976_2025-03-05T04:19:30.072904": {
    "overall_score": 0.6931263858093127,
    "timestamp": "2025-03-05T04:19:30.556935",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7474834536945198615_4838381025718951793_2025-03-05T04:19:31.722738": {
    "overall_score": 0.6693313105379858,
    "timestamp": "2025-03-05T04:19:31.827660",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.868421052631579,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_6398199393554021212_2000261660423112954_2025-03-05T04:21:39.082014": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:21:39.112934",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_6398199393554021212_7119390427812249516_2025-03-05T04:21:39.123544": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T04:21:39.156929",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_6398199393554021212_-3522281843847841441_2025-03-05T04:21:39.167338": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:21:39.199934",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_6398199393554021212_8422006319651678202_2025-03-05T04:21:39.210442": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T04:21:39.244120",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-782656831191057936_624213552764920580_2025-03-05T04:21:39.255930": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:21:39.290457",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-782656831191057936_7119390427812249516_2025-03-05T04:21:39.303610": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T04:21:39.346318",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-782656831191057936_-3522281843847841441_2025-03-05T04:21:39.361745": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:21:39.403403",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-782656831191057936_8422006319651678202_2025-03-05T04:21:39.415452": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T04:21:39.494761",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-9192860394077549563_-8174402848996694748_2025-03-05T04:21:39.523458": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:21:39.623441",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-9192860394077549563_7119390427812249516_2025-03-05T04:21:39.654755": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T04:21:39.711793",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-9192860394077549563_-3522281843847841441_2025-03-05T04:21:39.728478": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T04:21:39.781838",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-9192860394077549563_8422006319651678202_2025-03-05T04:21:39.799285": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T04:21:39.857697",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1621117142025547922_2401823887477659253_2025-03-05T04:22:16.338573": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:22:16.427897",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1621117142025547922_-2186471212117269777_2025-03-05T04:22:16.461501": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-05T04:22:16.559724",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1621117142025547922_-5485810463555870739_2025-03-05T04:22:18.711571": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:22:18.919822",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1621117142025547922_-3283193052290400534_2025-03-05T04:22:19.031268": {
    "overall_score": 0.6760975609756099,
    "timestamp": "2025-03-05T04:22:20.073234",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.88,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1271324561671592836_6975266711727043383_2025-03-05T04:22:25.107415": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:22:25.182492",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1271324561671592836_-2186471212117269777_2025-03-05T04:22:25.207670": {
    "overall_score": 0.728780487804878,
    "timestamp": "2025-03-05T04:22:25.275701",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.36000000000000004,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1271324561671592836_-5485810463555870739_2025-03-05T04:22:25.301173": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:22:25.368944",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1271324561671592836_-3283193052290400534_2025-03-05T04:22:25.392643": {
    "overall_score": 0.662652856665553,
    "timestamp": "2025-03-05T04:22:25.461226",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_6947954828975066895_8957354982287556268_2025-03-05T04:22:27.510952": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-05T04:22:27.582493",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_6947954828975066895_-2186471212117269777_2025-03-05T04:22:27.607530": {
    "overall_score": 0.738359201773836,
    "timestamp": "2025-03-05T04:22:27.683288",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.40909090909090906,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_6947954828975066895_-5485810463555870739_2025-03-05T04:22:27.711598": {
    "overall_score": 0.6931263858093127,
    "timestamp": "2025-03-05T04:22:27.789235",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_6947954828975066895_-3283193052290400534_2025-03-05T04:22:27.814339": {
    "overall_score": 0.6693313105379858,
    "timestamp": "2025-03-05T04:22:27.966040",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.868421052631579,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-8686542248528770757_5399687665886974177_2025-03-05T04:26:53.561172": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:26:53.599511",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8686542248528770757_-2679831713563229869_2025-03-05T04:26:53.613451": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T04:26:53.654459",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8686542248528770757_-2213192298199955142_2025-03-05T04:26:53.668580": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:26:53.708811",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8686542248528770757_1263745038693556235_2025-03-05T04:26:53.722348": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T04:26:53.764693",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2824918618929942977_-3683205838556616677_2025-03-05T04:26:53.781650": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:26:53.831827",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2824918618929942977_-2679831713563229869_2025-03-05T04:26:53.847364": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T04:26:53.894138",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2824918618929942977_-2213192298199955142_2025-03-05T04:26:53.909976": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:26:53.956236",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2824918618929942977_1263745038693556235_2025-03-05T04:26:53.972299": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T04:26:54.029744",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1739122243933662679_4725799101703029010_2025-03-05T04:26:54.049637": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:26:54.109256",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1739122243933662679_-2679831713563229869_2025-03-05T04:26:54.127611": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T04:26:54.186434",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1739122243933662679_-2213192298199955142_2025-03-05T04:26:54.209702": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T04:26:54.279047",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1739122243933662679_1263745038693556235_2025-03-05T04:26:54.302611": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T04:26:54.374479",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-77634713047994281_3442661736689419401_2025-03-05T04:29:45.727120": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:29:45.878829",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-77634713047994281_7152290797756470395_2025-03-05T04:29:45.949989": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T04:29:46.159353",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-77634713047994281_-2174394925440080061_2025-03-05T04:29:46.235947": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:29:46.395006",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-77634713047994281_-2306624700448372482_2025-03-05T04:29:46.635566": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-05T04:29:47.537655",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-4380139255159023219_-5090740648058316182_2025-03-05T04:29:47.614322": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:29:47.918875",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-4380139255159023219_7152290797756470395_2025-03-05T04:29:47.953370": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T04:29:48.124469",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-4380139255159023219_-2174394925440080061_2025-03-05T04:29:48.166855": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T04:29:48.277045",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-4380139255159023219_-2306624700448372482_2025-03-05T04:29:48.308069": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-05T04:29:48.409175",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_6788628016747418990_-4508523088447781383_2025-03-05T04:29:48.445991": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T04:29:48.579223",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_6788628016747418990_7152290797756470395_2025-03-05T04:29:48.616549": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T04:29:48.743020",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_6788628016747418990_-2174394925440080061_2025-03-05T04:29:48.782023": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T04:29:48.906348",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_6788628016747418990_-2306624700448372482_2025-03-05T04:29:48.938120": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-05T04:29:49.631879",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_2468107964380533405_6602171508592889873_2025-03-05T04:30:26.768785": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:30:26.845138",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_2468107964380533405_6542738023465430040_2025-03-05T04:30:26.872921": {
    "overall_score": 0.7112195121951219,
    "timestamp": "2025-03-05T04:30:26.947199",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_2468107964380533405_-6266247985528342779_2025-03-05T04:30:26.975195": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:30:27.049615",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_2468107964380533405_7158450555495661684_2025-03-05T04:30:27.076901": {
    "overall_score": 0.6760975609756099,
    "timestamp": "2025-03-05T04:30:27.150787",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.88,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.3,
          "completeness": 0.88,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_2135378158455925192_-1120981278444499303_2025-03-05T04:30:29.316547": {
    "overall_score": 0.7990243902439025,
    "timestamp": "2025-03-05T04:30:29.432442",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7200000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 8,
          "overlap_ratio": 0.8,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_2135378158455925192_6542738023465430040_2025-03-05T04:30:29.473029": {
    "overall_score": 0.728780487804878,
    "timestamp": "2025-03-05T04:30:29.673039",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.36000000000000004,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.4,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_2135378158455925192_-6266247985528342779_2025-03-05T04:30:30.661556": {
    "overall_score": 0.6643902439024392,
    "timestamp": "2025-03-05T04:30:30.791014",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_2135378158455925192_7158450555495661684_2025-03-05T04:30:30.831871": {
    "overall_score": 0.662652856665553,
    "timestamp": "2025-03-05T04:30:30.971101",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.2,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5014366439310417149_2211997338883622592_2025-03-05T04:30:33.448470": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-05T04:30:33.602724",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5014366439310417149_6542738023465430040_2025-03-05T04:30:33.653582": {
    "overall_score": 0.738359201773836,
    "timestamp": "2025-03-05T04:30:33.801480",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.40909090909090906,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5014366439310417149_-6266247985528342779_2025-03-05T04:30:33.859465": {
    "overall_score": 0.6931263858093127,
    "timestamp": "2025-03-05T04:30:34.003401",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5014366439310417149_7158450555495661684_2025-03-05T04:30:34.053111": {
    "overall_score": 0.6693313105379858,
    "timestamp": "2025-03-05T04:30:34.362673",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.868421052631579,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.868421052631579,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-2753318550340042489_1612439456047435144_2025-03-05T16:05:23.474661": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T16:05:23.504260",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2753318550340042489_7607953342365689033_2025-03-05T16:05:23.515018": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-05T16:05:23.542652",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2753318550340042489_5435199200771427312_2025-03-05T16:05:23.552886": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T16:05:23.580804",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2753318550340042489_8730388317846257847_2025-03-05T16:05:23.590998": {
    "overall_score": 0.700701637153358,
    "timestamp": "2025-03-05T16:05:23.618340",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "mistral7b_6268511707377185448_-6055269016642982044_2025-03-05T16:05:31.439728": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T16:05:31.470311",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 1.0,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.9,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 1.0,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 1.0,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 1.0,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 1.0,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "mistral7b_5201866012847681996_2303798335248034072_2025-03-05T16:07:54.402742": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T16:07:54.433168",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4_33323750906750126_1085381287505316274_2025-03-05T16:22:18.608839": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T16:22:18.648062",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_33323750906750126_-1393963861288386759_2025-03-05T16:22:18.659984": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T16:22:18.689807",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_33323750906750126_2047861146891684428_2025-03-05T16:22:18.700441": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T16:22:18.728545",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_33323750906750126_-3766962367880065284_2025-03-05T16:22:18.738848": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T16:22:18.767653",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_4280990493851046035_-3829184590336435896_2025-03-05T16:22:20.619609": {
    "overall_score": 0.8107317073170732,
    "timestamp": "2025-03-05T16:22:20.661161",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.78,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_4280990493851046035_-1393963861288386759_2025-03-05T16:22:20.673674": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T16:22:20.704375",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_4280990493851046035_2047861146891684428_2025-03-05T16:22:20.714647": {
    "overall_score": 0.6543781993375488,
    "timestamp": "2025-03-05T16:22:20.743676",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.941358024691358,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_4280990493851046035_-3766962367880065284_2025-03-05T16:22:20.754420": {
    "overall_score": 0.612628726287263,
    "timestamp": "2025-03-05T16:22:20.782712",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6111111111111112,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-601552231960076183_807671480214524688_2025-03-05T16:23:45.799783": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-05T16:23:45.833404",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-601552231960076183_-1393963861288386759_2025-03-05T16:23:45.845512": {
    "overall_score": 0.738359201773836,
    "timestamp": "2025-03-05T16:23:45.878321",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.40909090909090906,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.45454545454545453,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-601552231960076183_2047861146891684428_2025-03-05T16:23:45.889695": {
    "overall_score": 0.6771618625277163,
    "timestamp": "2025-03-05T16:23:45.918983",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-601552231960076183_-3766962367880065284_2025-03-05T16:23:45.930339": {
    "overall_score": 0.6843728911597418,
    "timestamp": "2025-03-05T16:23:45.959757",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9565217391304348,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.9565217391304348,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-6893030278868027377_-1873454982877141351_2025-03-05T16:34:48.333252": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T16:34:48.373126",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-6893030278868027377_-51185045356486866_2025-03-05T16:34:48.384354": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T16:34:48.414535",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-6893030278868027377_8039173526107478161_2025-03-05T16:34:48.425421": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T16:34:48.455992",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-6893030278868027377_-799174047509232968_2025-03-05T16:34:48.467112": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T16:34:48.498289",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-8314501640482334823_-2032770134435170446_2025-03-05T16:34:50.335952": {
    "overall_score": 0.8107317073170732,
    "timestamp": "2025-03-05T16:34:50.367420",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.78,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8314501640482334823_-51185045356486866_2025-03-05T16:34:50.378608": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T16:34:50.409203",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8314501640482334823_8039173526107478161_2025-03-05T16:34:50.420359": {
    "overall_score": 0.6543781993375488,
    "timestamp": "2025-03-05T16:34:50.451312",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.941358024691358,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8314501640482334823_-799174047509232968_2025-03-05T16:34:50.463328": {
    "overall_score": 0.612628726287263,
    "timestamp": "2025-03-05T16:34:50.495331",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6111111111111112,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-6893030278868027377_-1873454982877141351_2025-03-05T16:35:57.595732": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T16:35:57.596043",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-6893030278868027377_-51185045356486866_2025-03-05T16:35:57.610822": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T16:35:57.611187",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-6893030278868027377_8039173526107478161_2025-03-05T16:35:57.624288": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T16:35:57.624566",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-6893030278868027377_-799174047509232968_2025-03-05T16:35:57.636921": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T16:35:57.637215",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-8314501640482334823_-2032770134435170446_2025-03-05T16:35:59.606331": {
    "overall_score": 0.8107317073170732,
    "timestamp": "2025-03-05T16:35:59.606603",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.78,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8314501640482334823_-51185045356486866_2025-03-05T16:35:59.618466": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T16:35:59.618728",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8314501640482334823_8039173526107478161_2025-03-05T16:35:59.630530": {
    "overall_score": 0.6543781993375488,
    "timestamp": "2025-03-05T16:35:59.630791",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.941358024691358,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8314501640482334823_-799174047509232968_2025-03-05T16:35:59.642705": {
    "overall_score": 0.612628726287263,
    "timestamp": "2025-03-05T16:35:59.642949",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6111111111111112,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5834859469663929554_2471640790183085752_2025-03-05T17:30:12.170875": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T17:30:12.202886",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5834859469663929554_69481307864026263_2025-03-05T17:30:12.213932": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T17:30:12.245528",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5834859469663929554_-2277112215013191176_2025-03-05T17:30:12.256022": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T17:30:12.287312",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5834859469663929554_-8084857903058120971_2025-03-05T17:30:12.297888": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T17:30:12.329245",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_4978446959327996590_-1583788519920817389_2025-03-05T17:30:14.342875": {
    "overall_score": 0.8107317073170732,
    "timestamp": "2025-03-05T17:30:14.385375",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.78,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 13,
          "overlap_ratio": 0.8666666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_4978446959327996590_69481307864026263_2025-03-05T17:30:14.397074": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-05T17:30:14.429570",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_4978446959327996590_-2277112215013191176_2025-03-05T17:30:14.440256": {
    "overall_score": 0.6543781993375488,
    "timestamp": "2025-03-05T17:30:14.471267",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.941358024691358,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.941358024691358,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_4978446959327996590_-8084857903058120971_2025-03-05T17:30:14.482201": {
    "overall_score": 0.612628726287263,
    "timestamp": "2025-03-05T17:30:14.513778",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6111111111111112,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.6111111111111112,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-4859158868162570527_-8919451183321595029_2025-03-05T18:42:53.110103": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:42:53.144293",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-4859158868162570527_-8767245410307237490_2025-03-05T18:42:53.157325": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:42:53.190038",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-4859158868162570527_183395121584246632_2025-03-05T18:42:53.201828": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:42:53.235434",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-4859158868162570527_-1434347485225648506_2025-03-05T18:42:53.247827": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:42:53.281096",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1771044373942530602_2136587874260921834_2025-03-05T18:44:59.897137": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:44:59.936497",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1771044373942530602_-4951455097572370841_2025-03-05T18:44:59.948513": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:44:59.981191",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1771044373942530602_-4942214456356889665_2025-03-05T18:44:59.992401": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:45:00.026078",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1771044373942530602_-3757078326143909904_2025-03-05T18:45:00.077462": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:45:00.117927",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-7028135319214881520_-917444501126737138_2025-03-05T18:49:00.290897": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:49:00.329822",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-7028135319214881520_8808730462639317642_2025-03-05T18:49:00.341831": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:49:00.375694",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-7028135319214881520_4553256537916672223_2025-03-05T18:49:00.387534": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:49:00.421044",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-7028135319214881520_-3939585813830093615_2025-03-05T18:49:00.432806": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:49:00.466744",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5656231093977206376_7512099969577460527_2025-03-05T18:50:24.215541": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:50:24.250234",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5656231093977206376_-3627855535634307219_2025-03-05T18:50:24.262134": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:50:24.296330",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5656231093977206376_-1008181825485783489_2025-03-05T18:50:24.307729": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:50:24.341817",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5656231093977206376_-6130852691184042067_2025-03-05T18:50:24.353381": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:50:24.387623",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-7319698488844426426_-5855310097869217962_2025-03-05T18:53:30.226872": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:53:30.270735",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-7319698488844426426_1155430181239547755_2025-03-05T18:53:30.284392": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:53:30.321027",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-7319698488844426426_-5732262793425691189_2025-03-05T18:53:30.334046": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:53:30.370453",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-7319698488844426426_5250721669529099478_2025-03-05T18:53:30.383124": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:53:30.419766",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_2613032726912114439_-2502275688678009956_2025-03-05T18:57:10.526889": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:57:10.562167",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_2613032726912114439_490318895013715537_2025-03-05T18:57:10.574423": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:57:10.610008",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_2613032726912114439_4582617281632032917_2025-03-05T18:57:10.621978": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:57:10.657482",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_2613032726912114439_-5320978069988846832_2025-03-05T18:57:10.669710": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:57:10.704859",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_9157033412290692777_-652793818804577574_2025-03-05T18:58:19.530827": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:58:19.574324",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_9157033412290692777_-4901481185373182280_2025-03-05T18:58:19.587901": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:58:19.624061",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_9157033412290692777_464846269313821924_2025-03-05T18:58:19.636542": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:58:19.672769",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_9157033412290692777_-3935506118167523965_2025-03-05T18:58:19.684881": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:58:19.721633",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T18:59:19.157217": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T18:59:19.195616",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T18:59:19.208440": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T18:59:19.244986",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T18:59:19.257170": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T18:59:19.293562",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T18:59:19.305603": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T18:59:19.342613",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T19:09:05.064883": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:09:05.065082",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T19:09:05.085541": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:09:05.085668",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T19:09:05.101962": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:09:05.102050",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T19:09:05.116907": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:09:05.117094",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T19:10:21.233334": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:10:21.233467",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T19:10:21.247505": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:10:21.247628",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T19:10:21.261012": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:10:21.261110",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T19:10:21.274638": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:10:21.274734",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T19:13:26.456374": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:13:26.456499",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T19:13:26.472327": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:13:26.472422",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T19:13:26.486191": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:13:26.486271",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T19:13:26.499949": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:13:26.500030",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T19:14:47.166688": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:14:47.166788",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T19:14:47.180273": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:14:47.180356",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T19:14:47.194364": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:14:47.194444",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T19:14:47.207745": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:14:47.207825",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3942418693622672825_-9091678784926691509_2025-03-05T19:15:28.084448": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:15:28.084553",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3942418693622672825_2806814138253513932_2025-03-05T19:15:28.098957": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:15:28.099086",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3942418693622672825_2648407347932072142_2025-03-05T19:15:28.113636": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:15:28.113723",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3942418693622672825_238662507886021858_2025-03-05T19:15:28.127794": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:15:28.127884",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5549102417721113176_1444765225958436199_2025-03-05T19:49:27.289219": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T19:49:27.328859",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5549102417721113176_-5074152113953080318_2025-03-05T19:49:27.343125": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T19:49:27.440676",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5549102417721113176_-8026598023057666443_2025-03-05T19:49:27.455249": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T19:49:27.494254",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5549102417721113176_-2054112704138388383_2025-03-05T19:49:27.508935": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T19:49:27.547706",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5215269506715516163_1878473980666824410_2025-03-05T20:06:58.770364": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T20:06:58.808163",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5215269506715516163_6366341002593560294_2025-03-05T20:06:58.823021": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T20:06:58.861441",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5215269506715516163_-6809060304162761573_2025-03-05T20:06:58.875626": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T20:06:58.915004",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5215269506715516163_-8412684470105755699_2025-03-05T20:06:58.929399": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T20:06:58.967982",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "mistral7b_6185616628164063782_-4744519834780956294_2025-03-05T20:07:31.955875": {
    "overall_score": 0.7170731707317075,
    "timestamp": "2025-03-05T20:07:32.015489",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.5,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.45,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.5,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.5,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.5,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.5,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "mistral7b_7976071916187541772_7071761063279276092_2025-03-05T20:07:45.498397": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-05T20:07:45.547677",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4_5215269506715516163_1878473980666824410_2025-03-05T20:19:26.391286": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T20:19:26.391793",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5215269506715516163_6366341002593560294_2025-03-05T20:19:26.548556": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T20:19:26.548828",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5215269506715516163_-6809060304162761573_2025-03-05T20:19:26.563313": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T20:19:26.563757",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5215269506715516163_-8412684470105755699_2025-03-05T20:19:26.578917": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T20:19:26.579147",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7702851830873029755_5525844840592721207_2025-03-05T20:24:16.879815": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T20:24:16.924110",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7702851830873029755_3774428980079787393_2025-03-05T20:24:16.938346": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T20:24:16.978249",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7702851830873029755_5569529867025298342_2025-03-05T20:24:16.992424": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T20:24:17.031094",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7702851830873029755_-9083597247590423680_2025-03-05T20:24:17.045719": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T20:24:17.084554",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_3847914653817855959_-5840540806690328950_2025-03-05T20:54:23.741497": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T20:54:23.789701",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_3847914653817855959_2726521777165646734_2025-03-05T20:54:23.805508": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T20:54:23.845703",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_3847914653817855959_930763691948068000_2025-03-05T20:54:23.860402": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T20:54:23.901547",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_3847914653817855959_-2433393926978365239_2025-03-05T20:54:23.916123": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T20:54:23.957005",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-536546144661659170_6137235581409216431_2025-03-05T22:12:28.197958": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-05T22:12:28.249823",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-536546144661659170_-1842375034593382954_2025-03-05T22:12:28.264946": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-05T22:12:28.306354",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-536546144661659170_-9181535747115587943_2025-03-05T22:12:28.320800": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-05T22:12:28.361316",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-536546144661659170_-3142452420758836632_2025-03-05T22:12:28.492926": {
    "overall_score": 0.6365853658536585,
    "timestamp": "2025-03-05T22:12:28.534253",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_9069413590449641823_-5290320759301947367_2025-03-07T02:47:08.619033": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T02:47:08.660146",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_6436472063187359105_5883504601400115386_2025-03-07T02:58:03.961159": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T02:58:04.009141",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-6995678918098942706_-5287171487159055991_2025-03-07T02:58:51.988926": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T02:58:52.030577",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_6618317836097449239_8881703606979731128_2025-03-07T03:37:44.720829": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T03:37:44.766298",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_5857974878762477684_-8700022337206868017_2025-03-07T03:38:09.540508": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T03:38:09.585574",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-1379380436522503630_4435989344125685455_2025-03-07T03:38:50.038295": {
    "overall_score": 0.5092218350754937,
    "timestamp": "2025-03-07T03:38:50.083394",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.46258503401360546,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.3666666666666667,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2,
          "completeness": 0.46258503401360546,
          "structure_score": 0.3666666666666667,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-3998886521263494771_-4176227426164448958_2025-03-07T15:44:18.946350": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:44:19.004542",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-3998886521263494771_3392163478384131587_2025-03-07T15:44:19.020295": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:44:19.061651",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-3998886521263494771_-645159486114477373_2025-03-07T15:44:19.076677": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:44:19.127435",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-3998886521263494771_-7124837872347363243_2025-03-07T15:44:19.143630": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:44:19.188369",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5125607518841898279_-1095357582947943160_2025-03-07T15:45:32.072713": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:45:32.115872",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5125607518841898279_2991161794547244238_2025-03-07T15:45:32.130745": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:45:32.182342",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5125607518841898279_3592522739610517984_2025-03-07T15:45:32.201375": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:45:32.244847",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5125607518841898279_4364804904415311209_2025-03-07T15:45:32.260754": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:45:32.302536",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-1170149638236818021_-6607574150627554469_2025-03-07T15:46:29.483077": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:46:29.525662",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-1170149638236818021_-8178840282300819662_2025-03-07T15:46:29.540707": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:46:29.599604",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-1170149638236818021_-8695189437335039997_2025-03-07T15:46:29.619591": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:46:29.666013",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-1170149638236818021_-7035227698107179801_2025-03-07T15:46:29.681570": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:46:29.724554",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-1170149638236818021_5911031824921798659_2025-03-07T15:46:29.740342": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:46:29.784098",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-1170149638236818021_-3779888141703686709_2025-03-07T15:46:29.799493": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:46:29.843680",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-4339842658369163002_-5419481532709863082_2025-03-07T15:49:12.522849": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:49:12.568256",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-4339842658369163002_-4966216220385586910_2025-03-07T15:49:12.583379": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:49:12.626843",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-4339842658369163002_1939771246501814514_2025-03-07T15:49:12.642278": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:49:12.691661",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-4339842658369163002_2769336707618605160_2025-03-07T15:49:12.708231": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:49:12.764156",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-4339842658369163002_-1867041440693169576_2025-03-07T15:49:12.783371": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:49:12.828815",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-4339842658369163002_7320339154450261222_2025-03-07T15:49:12.844163": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:49:12.887693",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-8705470264528233787_-8087728537126303330_2025-03-07T15:56:09.414982": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:56:09.508198",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8705470264528233787_5384207408776967953_2025-03-07T15:56:09.526037": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:56:09.593999",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8705470264528233787_-5402743769087384485_2025-03-07T15:56:09.611073": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:56:09.657780",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8705470264528233787_-3138467218333796292_2025-03-07T15:56:09.673728": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:56:09.741456",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-8705470264528233787_-1889298425471874348_2025-03-07T15:56:09.759324": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:56:09.805350",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-8705470264528233787_6918880637308838680_2025-03-07T15:56:09.821377": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:56:09.868317",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_316020191617785703_-8559685943259356008_2025-03-07T15:56:48.650342": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:56:48.712771",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_316020191617785703_3651562982493233459_2025-03-07T15:56:48.729383": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:56:48.775490",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_316020191617785703_-3472614393279165743_2025-03-07T15:56:48.791121": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:56:48.838002",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_316020191617785703_4692748181849471512_2025-03-07T15:56:48.853564": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:56:48.899857",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_316020191617785703_-7926455511098448049_2025-03-07T15:56:48.932119": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:56:48.979717",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_316020191617785703_-6003663073413208948_2025-03-07T15:56:48.999416": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:56:49.048104",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-8490585011321810790_3977456634931231542_2025-03-07T15:57:41.373601": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:57:41.424941",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-8490585011321810790_-768436447416509999_2025-03-07T15:57:41.441293": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:57:41.490412",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-8490585011321810790_7011966856983340359_2025-03-07T15:57:41.507020": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:57:41.557960",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-8490585011321810790_-3959688329584983785_2025-03-07T15:57:41.588600": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:57:41.649785",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-8490585011321810790_-1884184215249222384_2025-03-07T15:57:41.668613": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:57:41.716701",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-8490585011321810790_-1441896658407201350_2025-03-07T15:57:41.733154": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:57:41.780901",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_8439065498009897561_6347452101204451410_2025-03-07T15:59:49.108642": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T15:59:49.158328",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_8439065498009897561_6469519620197458028_2025-03-07T15:59:49.175536": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T15:59:49.262317",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_8439065498009897561_-1226792905765292624_2025-03-07T15:59:49.302158": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T15:59:49.358735",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_8439065498009897561_-5708132610410358990_2025-03-07T15:59:49.377220": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T15:59:49.430471",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_8439065498009897561_-2074667431477939898_2025-03-07T15:59:49.447200": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:59:49.497142",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_8439065498009897561_-2588188478843736127_2025-03-07T15:59:49.513439": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T15:59:49.563249",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-5678504058950209769_228490064798404163_2025-03-07T16:05:15.663017": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T16:05:15.712250",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5678504058950209769_6246288557644875490_2025-03-07T16:05:15.729290": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T16:05:15.779072",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5678504058950209769_5848714765215395715_2025-03-07T16:05:15.812333": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T16:05:15.862474",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5678504058950209769_-5599392219009271202_2025-03-07T16:05:15.879170": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T16:05:15.928821",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-5678504058950209769_2504810594790215757_2025-03-07T16:05:15.945827": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:05:15.997848",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-5678504058950209769_6541310234706654886_2025-03-07T16:05:16.017068": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:05:16.086972",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_5295694565300141965_6366004571124490325_2025-03-07T16:07:46.719900": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T16:07:46.771200",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5295694565300141965_-1247488157540133861_2025-03-07T16:07:46.805248": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T16:07:46.856690",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5295694565300141965_2569100156872298155_2025-03-07T16:07:46.873503": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T16:07:46.926217",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5295694565300141965_-8955318962548009153_2025-03-07T16:07:46.943231": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T16:07:46.994778",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_5295694565300141965_-6515117687666111593_2025-03-07T16:07:47.011897": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:07:47.086518",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_5295694565300141965_3906113277491107265_2025-03-07T16:07:47.105988": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:07:47.157849",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-2946377626368170359_7847163497734336506_2025-03-07T16:12:27.750462": {
    "overall_score": 0.7580619347766511,
    "timestamp": "2025-03-07T16:12:27.798996",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.864,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.5955056179775281,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 48,
          "overlap_ratio": 0.96,
          "completeness": 0.5955056179775281,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-2946377626368170359_8035052657253760242_2025-03-07T16:12:27.815154": {
    "overall_score": 0.5667927286014434,
    "timestamp": "2025-03-07T16:12:27.866174",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.18000000000000002,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.25692883895131086,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.2,
          "completeness": 0.25692883895131086,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-2946377626368170359_-5760007688466829901_2025-03-07T16:12:27.882319": {
    "overall_score": 0.5186158764958436,
    "timestamp": "2025-03-07T16:12:27.952027",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.22846441947565543,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.12,
          "completeness": 0.22846441947565543,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-2946377626368170359_3442329318604900877_2025-03-07T16:12:27.971739": {
    "overall_score": 0.5160537133461224,
    "timestamp": "2025-03-07T16:12:28.026628",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.09000000000000001,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.14831460674157304,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.1,
          "completeness": 0.14831460674157304,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "claude-3_-2946377626368170359_-5724927951568348609_2025-03-07T16:12:28.044827": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:12:28.096670",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "gemini-pro_-2946377626368170359_-2172005312687771608_2025-03-07T16:12:28.113324": {
    "overall_score": 0.7147317073170731,
    "timestamp": "2025-03-07T16:12:28.162676",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.28800000000000003,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 16,
          "overlap_ratio": 0.32,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gemini-pro"
  },
  "gpt4_-3316216536290676008_-6222413797410298880_2025-03-07T16:14:58.871960": {
    "overall_score": 0.8090592334494773,
    "timestamp": "2025-03-07T16:14:58.926134",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7714285714285714,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-3316216536290676008_-854755470068407854_2025-03-07T16:14:58.967848": {
    "overall_score": 0.7337979094076654,
    "timestamp": "2025-03-07T16:14:59.023042",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3857142857142857,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-3316216536290676008_-4261380302447610352_2025-03-07T16:14:59.040769": {
    "overall_score": 0.6772323895222309,
    "timestamp": "2025-03-07T16:14:59.092483",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9870550161812298,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-3316216536290676008_-8476540810694497506_2025-03-07T16:14:59.109831": {
    "overall_score": 0.620202293562464,
    "timestamp": "2025-03-07T16:14:59.162822",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6407766990291263,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-7913113158876488469_-5914197522319598660_2025-03-07T16:14:59.202281": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-07T16:14:59.255792",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-7913113158876488469_-854755470068407854_2025-03-07T16:14:59.272850": {
    "overall_score": 0.7223946784922396,
    "timestamp": "2025-03-07T16:14:59.323746",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-7913113158876488469_-4261380302447610352_2025-03-07T16:14:59.340971": {
    "overall_score": 0.6771618625277163,
    "timestamp": "2025-03-07T16:14:59.393355",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-7913113158876488469_-8476540810694497506_2025-03-07T16:14:59.410469": {
    "overall_score": 0.6552106430155211,
    "timestamp": "2025-03-07T16:14:59.462775",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5844102678798323493_9141923308684159208_2025-03-07T16:14:59.482250": {
    "overall_score": 0.8071294559099438,
    "timestamp": "2025-03-07T16:14:59.537976",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7615384615384615,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5844102678798323493_-854755470068407854_2025-03-07T16:14:59.555741": {
    "overall_score": 0.7125703564727955,
    "timestamp": "2025-03-07T16:14:59.607252",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5844102678798323493_-4261380302447610352_2025-03-07T16:14:59.624168": {
    "overall_score": 0.6833020637898687,
    "timestamp": "2025-03-07T16:14:59.676295",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5844102678798323493_-8476540810694497506_2025-03-07T16:14:59.694031": {
    "overall_score": 0.63617750224325,
    "timestamp": "2025-03-07T16:14:59.748297",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2076923076923077,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.717391304347826,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_23842231443532015_-804488637304538515_2025-03-07T16:16:40.016008": {
    "overall_score": 0.8090592334494773,
    "timestamp": "2025-03-07T16:16:40.069117",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7714285714285714,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 12,
          "overlap_ratio": 0.8571428571428571,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_23842231443532015_-4441610243616177841_2025-03-07T16:16:40.086902": {
    "overall_score": 0.7337979094076654,
    "timestamp": "2025-03-07T16:16:40.142805",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3857142857142857,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.42857142857142855,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_23842231443532015_3965153155400919260_2025-03-07T16:16:40.178778": {
    "overall_score": 0.6772323895222309,
    "timestamp": "2025-03-07T16:16:40.233502",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2571428571428571,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9870550161812298,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.2857142857142857,
          "completeness": 0.9870550161812298,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_23842231443532015_-7792111677471316655_2025-03-07T16:16:40.251393": {
    "overall_score": 0.620202293562464,
    "timestamp": "2025-03-07T16:16:40.305294",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.6407766990291263,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.6407766990291263,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-3552305384110050005_6027300811781278538_2025-03-07T16:16:40.325141": {
    "overall_score": 0.8022172949002218,
    "timestamp": "2025-03-07T16:16:40.384130",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 9,
          "overlap_ratio": 0.8181818181818182,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-3552305384110050005_-4441610243616177841_2025-03-07T16:16:40.403446": {
    "overall_score": 0.7223946784922396,
    "timestamp": "2025-03-07T16:16:40.479337",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.32727272727272727,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.36363636363636365,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-3552305384110050005_3965153155400919260_2025-03-07T16:16:40.497334": {
    "overall_score": 0.6771618625277163,
    "timestamp": "2025-03-07T16:16:40.551638",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-3552305384110050005_-7792111677471316655_2025-03-07T16:16:40.569619": {
    "overall_score": 0.6552106430155211,
    "timestamp": "2025-03-07T16:16:40.623591",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.24545454545454545,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7857142857142857,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.2727272727272727,
          "completeness": 0.7857142857142857,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7958644904222401563_1416658951248016724_2025-03-07T16:16:40.644515": {
    "overall_score": 0.8071294559099438,
    "timestamp": "2025-03-07T16:16:40.699316",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.7615384615384615,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 11,
          "overlap_ratio": 0.8461538461538461,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7958644904222401563_-4441610243616177841_2025-03-07T16:16:40.717242": {
    "overall_score": 0.7125703564727955,
    "timestamp": "2025-03-07T16:16:40.771910",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7958644904222401563_3965153155400919260_2025-03-07T16:16:40.789665": {
    "overall_score": 0.6833020637898687,
    "timestamp": "2025-03-07T16:16:40.843345",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.27692307692307694,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3076923076923077,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7958644904222401563_-7792111677471316655_2025-03-07T16:16:40.860810": {
    "overall_score": 0.63617750224325,
    "timestamp": "2025-03-07T16:16:40.917911",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.2076923076923077,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.717391304347826,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.23076923076923078,
          "completeness": 0.717391304347826,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_5654013880025781533_3597660788511734503_2025-03-07T16:27:10.740325": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T16:27:10.796937",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_5654013880025781533_-4953660029699441970_2025-03-07T16:27:10.815089": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-07T16:27:10.891825",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_5654013880025781533_-1377568888435112101_2025-03-07T16:27:10.911313": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T16:27:10.972950",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_5654013880025781533_3990897331945289663_2025-03-07T16:27:10.992962": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-07T16:27:11.049022",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7204861254820128828_-6482370229882324133_2025-03-07T16:27:11.068605": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T16:27:11.123837",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_7204861254820128828_-4953660029699441970_2025-03-07T16:27:11.141219": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-07T16:27:11.194999",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_7204861254820128828_-1377568888435112101_2025-03-07T16:27:11.212477": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T16:27:11.266782",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_7204861254820128828_3990897331945289663_2025-03-07T16:27:11.284233": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-07T16:27:11.355462",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1327233902942962261_-3914972669567391918_2025-03-07T16:27:11.375353": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T16:27:11.432801",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1327233902942962261_-4953660029699441970_2025-03-07T16:27:11.451341": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-07T16:27:11.508813",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1327233902942962261_-1377568888435112101_2025-03-07T16:27:11.529737": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-07T16:27:11.586810",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1327233902942962261_3990897331945289663_2025-03-07T16:27:11.605102": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-07T16:27:11.661680",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1310879721133420686_8815516608168654198_2025-03-07T17:09:51.740286": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:09:51.822752",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1310879721133420686_3217768414285360570_2025-03-07T17:09:51.841986": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-07T17:09:51.900882",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1310879721133420686_7131057178511390158_2025-03-07T17:09:51.920491": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T17:09:51.980304",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1310879721133420686_-6514503936827628064_2025-03-07T17:09:51.999079": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-07T17:09:52.081573",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-3471055799518718567_5499562778597173255_2025-03-07T17:09:52.103193": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:09:52.166069",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-3471055799518718567_3217768414285360570_2025-03-07T17:09:52.184613": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-07T17:09:52.247808",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-3471055799518718567_7131057178511390158_2025-03-07T17:09:52.266390": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T17:09:52.326951",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-3471055799518718567_-6514503936827628064_2025-03-07T17:09:52.345478": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-07T17:09:52.403675",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-3804585594466893739_7449179180401256612_2025-03-07T17:09:52.424688": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:09:52.482371",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-3804585594466893739_3217768414285360570_2025-03-07T17:09:52.500729": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-07T17:09:52.558420",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-3804585594466893739_7131057178511390158_2025-03-07T17:09:52.576855": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-07T17:09:52.635576",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-3804585594466893739_-6514503936827628064_2025-03-07T17:09:52.654425": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-07T17:09:52.712529",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_-5211029117651762403_1274741892303045315_2025-03-07T17:11:36.889819": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:11:36.954433",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_-5211029117651762403_-7451787514734956374_2025-03-07T17:11:36.973921": {
    "overall_score": 0.7317073170731708,
    "timestamp": "2025-03-07T17:11:37.035435",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.375,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 5,
          "overlap_ratio": 0.4166666666666667,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_-5211029117651762403_-8198510498509660193_2025-03-07T17:11:37.055040": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T17:11:37.141437",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_-5211029117651762403_-6725039773149116661_2025-03-07T17:11:37.160820": {
    "overall_score": 0.6860674908118944,
    "timestamp": "2025-03-07T17:11:37.221726",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.9041095890410958,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 0.9041095890410958,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1417457496551204186_-3625536101600070827_2025-03-07T17:11:37.242681": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:11:37.304063",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1417457496551204186_-7451787514734956374_2025-03-07T17:11:37.323257": {
    "overall_score": 0.702439024390244,
    "timestamp": "2025-03-07T17:11:37.383126",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1417457496551204186_-8198510498509660193_2025-03-07T17:11:37.402463": {
    "overall_score": 0.6731707317073171,
    "timestamp": "2025-03-07T17:11:37.465062",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1417457496551204186_-6725039773149116661_2025-03-07T17:11:37.486190": {
    "overall_score": 0.6350071736011478,
    "timestamp": "2025-03-07T17:11:37.549572",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.15,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.7764705882352941,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 2,
          "overlap_ratio": 0.16666666666666666,
          "completeness": 0.7764705882352941,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_1560682065154499322_2578044163620337684_2025-03-07T17:11:37.570758": {
    "overall_score": 0.8048780487804879,
    "timestamp": "2025-03-07T17:11:37.628838",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.75,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 10,
          "overlap_ratio": 0.8333333333333334,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "claude3_1560682065154499322_-7451787514734956374_2025-03-07T17:11:37.647562": {
    "overall_score": 0.7170731707317073,
    "timestamp": "2025-03-07T17:11:37.706456",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 1.0,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 1.0,
          "is_fallback": true
        }
      }
    },
    "model": "claude3"
  },
  "mistral7b_1560682065154499322_-8198510498509660193_2025-03-07T17:11:37.725294": {
    "overall_score": 0.6878048780487807,
    "timestamp": "2025-03-07T17:11:37.785123",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.3,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.8,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.3333333333333333,
          "completeness": 1.0,
          "structure_score": 0.8,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "gpt4all_1560682065154499322_-6725039773149116661_2025-03-07T17:11:37.804599": {
    "overall_score": 0.6597097869712875,
    "timestamp": "2025-03-07T17:11:37.889284",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.225,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.8354430379746836,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.25,
          "completeness": 0.8354430379746836,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4all"
  },
  "gpt4_7752734199790083407_3090025732252187382_2025-03-08T09:43:47.554096": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T09:43:47.629459",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_91688102341901650_8642165922533290497_2025-03-08T09:43:48.205840": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T09:43:48.278994",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_7662024285295943344_5384575377991334355_2025-03-08T09:45:48.473652": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T09:45:48.536427",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-9126797379962446549_933708957568936226_2025-03-08T09:48:11.361252": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T09:48:11.430409",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-1001133647356246359_4229268209745149405_2025-03-08T09:49:21.659455": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T09:49:21.722942",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-2938647445953417769_-1384477604213386268_2025-03-08T14:45:42.722177": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T14:45:42.838519",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "gpt4_-5830691729555229075_4152838567777570531_2025-03-08T14:46:42.864632": {
    "overall_score": 0.41937282229965156,
    "timestamp": "2025-03-08T14:46:42.928543",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.06,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.24489795918367346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.16666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 1,
          "overlap_ratio": 0.06666666666666667,
          "completeness": 0.24489795918367346,
          "structure_score": 0.16666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "gpt4"
  },
  "mistral7b_3003486821448501593_4443345395512259231_2025-03-09T00:51:54.657058": {
    "overall_score": 0.6439024390243903,
    "timestamp": "2025-03-09T00:51:54.720795",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 0,
          "overlap_ratio": 0.0,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.0,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 0,
          "overlap_ratio": 0.0,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 1.0,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 0,
          "overlap_ratio": 0.0,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.9,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 0,
          "overlap_ratio": 0.0,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 0,
          "overlap_ratio": 0.0,
          "completeness": 1.0,
          "structure_score": 0.9,
          "is_fallback": true
        }
      }
    },
    "model": "mistral7b"
  },
  "claude-3_-7341714081562196601_-5553010418232363768_2025-03-13T11:59:28.580959": {
    "overall_score": 0.47778277321943724,
    "timestamp": "2025-03-13T11:59:28.650007",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.34946236559139787,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-3085620812742314265_-2038890922923221138_2025-03-13T11:59:28.692559": {
    "overall_score": 0.4800849061705694,
    "timestamp": "2025-03-13T11:59:28.756781",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.16363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39634146341463417,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_14709450347197131_-2038890922923221138_2025-03-13T11:59:28.788742": {
    "overall_score": 0.45818118466898955,
    "timestamp": "2025-03-13T11:59:28.856217",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.33163265306122447,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_1289625001730043687_-2038890922923221138_2025-03-13T11:59:28.891235": {
    "overall_score": 0.4692918013517484,
    "timestamp": "2025-03-13T11:59:28.957193",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39156626506024095,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_4747537741527740114_-2038890922923221138_2025-03-13T11:59:29.054401": {
    "overall_score": 0.4709424872026498,
    "timestamp": "2025-03-13T11:59:29.121858",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4012345679012346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-2424201893593798324_-2038890922923221138_2025-03-13T11:59:29.154933": {
    "overall_score": 0.4571914755692407,
    "timestamp": "2025-03-13T11:59:29.224288",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.12857142857142856,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3023255813953488,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_2819321151851951134_-7830924289749870711_2025-03-13T12:01:41.525619": {
    "overall_score": 0.47778277321943724,
    "timestamp": "2025-03-13T12:01:41.593195",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.34946236559139787,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_7342317644282169659_1340599496306939035_2025-03-13T12:01:41.627142": {
    "overall_score": 0.4800849061705694,
    "timestamp": "2025-03-13T12:01:41.692917",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.16363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39634146341463417,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-1978703185889469915_1340599496306939035_2025-03-13T12:01:41.751906": {
    "overall_score": 0.45818118466898955,
    "timestamp": "2025-03-13T12:01:41.864026",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.33163265306122447,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-565769205587933810_1340599496306939035_2025-03-13T12:01:41.899140": {
    "overall_score": 0.4692918013517484,
    "timestamp": "2025-03-13T12:01:41.966082",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39156626506024095,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_178163990130049104_1340599496306939035_2025-03-13T12:01:42.000046": {
    "overall_score": 0.4709424872026498,
    "timestamp": "2025-03-13T12:01:42.066493",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4012345679012346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-727500316295000550_1340599496306939035_2025-03-13T12:01:42.100031": {
    "overall_score": 0.4571914755692407,
    "timestamp": "2025-03-13T12:01:42.168053",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.12857142857142856,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3023255813953488,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-1191430278333908731_4550305483065517235_2025-03-13T12:06:55.373556": {
    "overall_score": 0.47778277321943724,
    "timestamp": "2025-03-13T12:06:55.448145",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.19285714285714284,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.34946236559139787,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 6,
          "overlap_ratio": 0.21428571428571427,
          "completeness": 0.34946236559139787,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-603557652437896847_-3533053329824548401_2025-03-13T12:06:55.485480": {
    "overall_score": 0.4800849061705694,
    "timestamp": "2025-03-13T12:06:55.552902",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.16363636363636364,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39634146341463417,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.18181818181818182,
          "completeness": 0.39634146341463417,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_3076836380276008116_-3533053329824548401_2025-03-13T12:06:55.586779": {
    "overall_score": 0.45818118466898955,
    "timestamp": "2025-03-13T12:06:55.653594",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.108,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.33163265306122447,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.12,
          "completeness": 0.33163265306122447,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-5935314444053308781_-3533053329824548401_2025-03-13T12:06:55.687011": {
    "overall_score": 0.4692918013517484,
    "timestamp": "2025-03-13T12:06:55.753287",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.39156626506024095,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.39156626506024095,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_1403217834734638256_-3533053329824548401_2025-03-13T12:06:55.787611": {
    "overall_score": 0.4709424872026498,
    "timestamp": "2025-03-13T12:06:55.854955",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.1125,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.4012345679012346,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 3,
          "overlap_ratio": 0.125,
          "completeness": 0.4012345679012346,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  },
  "claude-3_-1669380469365816440_-3533053329824548401_2025-03-13T12:06:55.889025": {
    "overall_score": 0.4571914755692407,
    "timestamp": "2025-03-13T12:06:55.954822",
    "metrics": {
      "accuracy": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Factual correctness of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "relevance": {
        "score": 0.12857142857142856,
        "weight": 0.8,
        "description": "How relevant the response is to the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "completeness": {
        "score": 0.3023255813953488,
        "weight": 0.7,
        "description": "How completely the response addresses all aspects of the query",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "coherence": {
        "score": 0.26666666666666666,
        "weight": 0.6,
        "description": "Logical flow and structure of the response",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      },
      "harmlessness": {
        "score": 0.7,
        "weight": 1.0,
        "description": "Absence of harmful, biased, or inappropriate content",
        "details": {
          "word_overlap": 4,
          "overlap_ratio": 0.14285714285714285,
          "completeness": 0.3023255813953488,
          "structure_score": 0.26666666666666666,
          "is_fallback": true
        }
      }
    },
    "model": "claude-3"
  }
}