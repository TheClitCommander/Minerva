{
  "models": {
    "gpt4": {
      "type": "advanced",
      "capabilities": {
        "text": 0.95,
        "reasoning": 0.95,
        "conversation": 0.95,
        "code": 0.92,
        "research": 0.90,
        "math": 0.88,
        "creativity": 0.85
      },
      "confidence_threshold": 0.7,
      "api_provider": "openai",
      "model_version": "gpt-4",
      "is_active": true
    },
    "claude3": {
      "type": "advanced",
      "capabilities": {
        "text": 0.93,
        "reasoning": 0.92,
        "conversation": 0.94,
        "code": 0.85,
        "research": 0.90,
        "math": 0.83,
        "creativity": 0.90
      },
      "confidence_threshold": 0.7,
      "api_provider": "anthropic",
      "model_version": "claude-3-opus",
      "is_active": true
    },
    "mistral7b": {
      "type": "general",
      "capabilities": {
        "text": 0.88,
        "reasoning": 0.84,
        "conversation": 0.86,
        "code": 0.79,
        "research": 0.76,
        "math": 0.72,
        "creativity": 0.80
      },
      "confidence_threshold": 0.65,
      "api_provider": "mistral",
      "model_version": "mistral-7b-instruct",
      "is_active": true
    },
    "llama2": {
      "type": "general",
      "capabilities": {
        "text": 0.85,
        "reasoning": 0.81,
        "conversation": 0.83,
        "code": 0.75,
        "research": 0.72,
        "math": 0.69,
        "creativity": 0.78
      },
      "confidence_threshold": 0.65,
      "api_provider": "metaai",
      "model_version": "llama-2-70b-chat",
      "is_active": true
    },
    "gpt4all": {
      "type": "local",
      "capabilities": {
        "text": 0.75,
        "reasoning": 0.70,
        "conversation": 0.72,
        "code": 0.65,
        "research": 0.60,
        "math": 0.60,
        "creativity": 0.65
      },
      "confidence_threshold": 0.6,
      "api_provider": "local",
      "model_version": "gpt4all-j",
      "is_active": true
    },
    "falcon": {
      "type": "specialized",
      "capabilities": {
        "text": 0.82,
        "reasoning": 0.78,
        "conversation": 0.80,
        "code": 0.70,
        "research": 0.75,
        "math": 0.68,
        "creativity": 0.85
      },
      "confidence_threshold": 0.63,
      "api_provider": "huggingface",
      "model_version": "falcon-40b-instruct",
      "is_active": true
    }
  },
  "routing": {
    "default_models": ["gpt4", "claude3"],
    "fallback_model": "mistral7b",
    "confidence_thresholds": {
      "simple": 0.6,
      "medium": 0.7,
      "complex": 0.8
    },
    "priority_tags": {
      "code": ["gpt4", "claude3", "mistral7b"],
      "math": ["gpt4", "claude3", "mistral7b"],
      "creative": ["claude3", "gpt4", "falcon"],
      "research": ["claude3", "gpt4", "mistral7b"],
      "general": ["gpt4", "claude3", "llama2"]
    }
  },
  "validation": {
    "min_score": 0.5,
    "preferred_score": 0.7,
    "rejection_criteria": ["repetition", "irrelevance", "self-reference", "hallucination", "toxic"],
    "quality_thresholds": {
      "excellent": 0.85,
      "good": 0.7,
      "acceptable": 0.5,
      "poor": 0.3
    },
    "complexity_adjustments": {
      "simple": -0.1,
      "medium": 0.0,
      "complex": 0.1
    }
  },
  "logging": {
    "transaction_tracking": true,
    "response_quality_metrics": true,
    "model_selection_rationale": true,
    "response_validation_details": true,
    "performance_metrics": true
  }
}
